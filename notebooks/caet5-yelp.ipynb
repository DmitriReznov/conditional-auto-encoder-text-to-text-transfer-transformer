{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "clean_caet5_yelp.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "TPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2lX5RL3iHRp",
    "colab_type": "text"
   },
   "source": [
    "# Installing CAET5"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "znTRv3Y51JB_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!git clone https://github.com/LeoLaugier/conditional-auto-encoder-text-to-text-transfer-transformer.git\n",
    "\n",
    "%cd conditional-auto-encoder-text-to-text-transfer-transformer \n",
    "\n",
    "!pip install ."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfkIfWfaqRw_",
    "colab_type": "text"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVxlULLxiTkS",
    "colab_type": "text"
   },
   "source": [
    "## TPU setting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z_mrIS4mHJUq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(\"Setting up GCS access...\")\n",
    "import tensorflow as tf\n",
    "import tensorflow_gcs_config\n",
    "from google.colab import auth\n",
    "# Set credentials for GCS reading/writing from Colab and TPU.\n",
    "TPU_TOPOLOGY = \"2x2\"\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "  TPU_ADDRESS = tpu.get_master()\n",
    "  print('Running on TPU:', TPU_ADDRESS)\n",
    "except ValueError:\n",
    "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "auth.authenticate_user()\n",
    "tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
    "tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
    "\n",
    "%env TPU_ADDRESS=$TPU_ADDRESS"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuuzZGvFqM60",
    "colab_type": "text"
   },
   "source": [
    "## GCS Settings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vTXY4EnKqXVL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"gs://yourbucket/\"  # @param { type: \"string\" }\n",
    "%env BASE_DIR = $base_dir\n",
    "models_dir_name = \"your_models_dir_name\" # @param { type: \"string\" }\n",
    "%env MODELS_DIR_NAME = $models_dir_name\n",
    "MODELS_DIR = os.path.join(base_dir, models_dir_name)\n",
    "model_size = \"large\"\n",
    "%env MODEL_SIZE = $model_size\n",
    "model_dir_counter = 1 # @param { type: \"integer\" }\n",
    "%env MODEL_DIR_COUNTER = $model_dir_counter\n",
    "bucket = \"yourbucket\" # @param { type: \"string\" }\n",
    "%env BUCKET = $bucket\n",
    "data_dir_name = \"your_data_dir\" # @param { type: \"string\" }\n",
    "%env DATA_DIR_NAME = $data_dir_name \n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55LppxOvr7S4",
    "colab_type": "text"
   },
   "source": [
    "## Other Settings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J4CD_7kEr_JS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "training_steps = 100000 # @param { type: \"integer\" }\n",
    "%env TRAINING_STEPS = $training_steps\n",
    "task = \"yelp\" # @param { type: \"string\" }\n",
    "mixture = \"mixture_%s\" %task \n",
    "%env MIXTURE = $mixture\n",
    "sequence_length_gin = os.path.join(\"sequence_lengths\", \"%s.gin\" % task)\n",
    "%env SEQUENCE_LENGTH_GIN = $sequence_length_gin\n",
    "control_codes_gin = os.path.join(\"control_codes\", \"%s.gin\" % task)\n",
    "%env CONTROL_CODES_GIN = $control_codes_gin"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xW7Gc0pRh-0U",
    "colab_type": "text"
   },
   "source": [
    "#Training CAET5"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uSEHCWnY28Oh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!caet5 --base_dir=\"${BASE_DIR}\" \\\n",
    "       --model_dir_name=\"${MODELS_DIR_NAME}\" \\\n",
    "       --model_size=\"${MODEL_SIZE}\" \\\n",
    "       --model_dir_counter=\"${MODEL_DIR_COUNTER}\" \\\n",
    "       --tpu=\"${TPU_ADDRESS}\" \\\n",
    "       --module_import=caet5.data.tasks \\\n",
    "       --use_model_api=True \\\n",
    "       --mode=\"finetune\" \\\n",
    "       --bucket=\"${BUCKET}\" \\\n",
    "       --data_raw_dir_name=\"yelp_processed\" \\\n",
    "       --train_steps=\"${TRAINING_STEPS}\" \\\n",
    "       --mixture_or_task=\"${MIXTURE}\" \\\n",
    "       --base_pretrained_model_dir=\"gs://t5-data/pretrained_models/\" \\\n",
    "       --gin_file=\"dataset.gin\" \\\n",
    "       --gin_file=\"objectives/denoise.gin\" \\\n",
    "       --gin_file=\"models/cae_bi.gin\" \\\n",
    "       --gin_file=\"train.gin\" \\\n",
    "       --gin_file=\"${SEQUENCE_LENGTH_GIN}\" \\\n",
    "       --gin_file=\"${CONTROL_CODES_GIN}\" \\\n",
    "       --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '2x2'\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZQsCFVKiECR",
    "colab_type": "text"
   },
   "source": [
    "# Evaluating CAET5\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XDcgctpfiHUM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!caet5 --base_dir=\"${BASE_DIR}\" \\\n",
    "       --model_dir_name=\"${MODELS_DIR_NAME}\" \\\n",
    "       --model_size=\"${MODEL_SIZE}\" \\\n",
    "       --model_dir_counter=\"${MODEL_DIR_COUNTER}\" \\\n",
    "       --tpu=\"${TPU_ADDRESS}\" \\\n",
    "       --module_import=caet5.data.tasks \\\n",
    "       --use_model_api=True \\\n",
    "       --mode=\"eval\" \\\n",
    "       --bucket=\"${BUCKET}\" \\\n",
    "       --mixture_or_task=\"${MIXTURE}\" \\\n",
    "       --base_pretrained_model_dir=\"gs://t5-data/pretrained_models/\" \\\n",
    "       --checkpoint_mode=\"latest\" \\\n",
    "       --gin_file=\"dataset.gin\" \\\n",
    "       --gin_file=\"models/cae_bi.gin\" \\\n",
    "       --gin_file=\"${SEQUENCE_LENGTH_GIN}\" \\\n",
    "       --gin_file=\"${CONTROL_CODES_GIN}\" \\\n",
    "       --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '2x2'\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVIUSKAgjRMY",
    "colab_type": "text"
   },
   "source": [
    "#Predicting / Inferring with CAET5"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XI2_31tpjU4w",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import re\n",
    "import time \n",
    "\n",
    "comment_attribute_pairs = [\n",
    "\n",
    "            {\"text\": \"these donuts have the perfect texture and taste .\",\n",
    "             \"Destination attribute\": \"negative\"},\n",
    "            {\"text\": \"these donuts have the perfect texture and taste .\",\n",
    "             \"Destination attribute\": \"positive\"},\n",
    "\n",
    "            {\"text\": \"good food for the price .\",\n",
    "             \"Destination attribute\": \"negative\"},\n",
    "            {\"text\": \"good food for the price .\",\n",
    "             \"Destination attribute\": \"positive\"},\n",
    "\n",
    "            {\"text\": \"a little dirty on the inside , but wonderful people that work there !\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "            {\"text\": \"a little dirty on the inside , but wonderful people that work there !\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "\n",
    "            {\"text\": \"i always order it when i go there and it is always awesome .\",\n",
    "             \"Destination attribute\": \"negative\"},\n",
    "            {\"text\": \"i always order it when i go there and it is always awesome .\",\n",
    "             \"Destination attribute\": \"positive\"},\n",
    "\n",
    "            {\"text\": \"the rest of the food there is good also and not very expensive .\",\n",
    "             \"Destination attribute\": \"negative\"},\n",
    "            {\"text\": \"the rest of the food there is good also and not very expensive .\",\n",
    "             \"Destination attribute\": \"positive\"},\n",
    "\n",
    "            {\"text\": \"great food , low prices , and huge quantity !\",\n",
    "             \"Destination attribute\": \"negative\"},\n",
    "            {\"text\": \"great food , low prices , and huge quantity !\",\n",
    "             \"Destination attribute\": \"positive\"},\n",
    "\n",
    "            {\"text\": \"so excited to have a chinese place near my office !\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "            {\"text\": \"this is my go to spot for chinese food .\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "\n",
    "            {\"text\": \"i guess i need to spell that out more clearly next time .\",\n",
    "             \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"i guess i need to spell that out more clearly next time .\",\n",
    "             \"Destination attribute\": \"negative\"},\n",
    "\n",
    "            {\"text\": \"the service the last time i went was just terrible .\",\n",
    "             \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"the service the last time i went was just terrible .\",\n",
    "             \"Destination attribute\": \"negative\"},\n",
    "\n",
    "            {\"text\": \"it has n't been for quite a few years .\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"it has n't been for quite a few years .\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "\n",
    "            {\"text\": \"the food here is n't very good .\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"the food here is n't very good .\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "\n",
    "            {\"text\": \"i am sad to see how much this place has gone downhill .\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"i am sad to see how much this place has gone downhill .\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "\n",
    "            {\"text\": \"never again will i go back to this restaurant .\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"never again will i go back to this restaurant .\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "\n",
    "            {\"text\": \"i would n't go here for a meal ever again .\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"i would n't go here for a meal ever again .\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "\n",
    "            {\"text\": \"but nothing show stopping .\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"but nothing show stopping .\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "\n",
    "            {\"text\": \"very rude , will not come back .\",\n",
    "                \"Destination attribute\": \"positive\"},\n",
    "            {\"text\": \"very rude , will not come back .\",\n",
    "                \"Destination attribute\": \"negative\"},\n",
    "        ]\n",
    "\n",
    "attribute_ids = {\"negative\": \"0\", \"positive\": \"1\"}\n",
    "\n",
    "comments = []\n",
    "for p in comment_attribute_pairs:\n",
    "    comments.append(p[\"text\"] + \"|dst_attribute:\" + attribute_ids[p[\"Destination attribute\"]])\n",
    "\n",
    "now = time.time()\n",
    "# Write out the input text to text files.\n",
    "\n",
    "model_dir = os.path.join(\"%s_%s\" % (MODELS_DIR, str(model_dir_counter)), model_size)\n",
    "predict_inputs_path = os.path.join(model_dir, \"predict_inputs_%d.txt\" % now)\n",
    "predict_outputs_path = os.path.join(model_dir, \"predict_outputs_%d.txt\" % now)\n",
    "# Manually apply preprocessing\n",
    "with tf.io.gfile.GFile(predict_inputs_path, \"w\") as f:\n",
    "    for c in comments:\n",
    "        c = re.sub(r'\\n', r\"\\\\n\", c, flags=re.S)\n",
    "        f.write(\"%s\\n\" % c.lower())\n",
    "\n",
    "predict_batch_size = len(comments)\n",
    "%env PREDICT_BATCH_SIZE = $predict_batch_size\n",
    "%env PREDICT_INPUTS_PATH = $predict_inputs_path\n",
    "%env PREDICT_OUTPUTS_PATH = $predict_outputs_path"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xjcnMNx9nVjZ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!caet5 --base_dir=\"${BASE_DIR}\" \\\n",
    "       --model_dir_name=\"${MODELS_DIR_NAME}\" \\\n",
    "       --model_size=\"${MODEL_SIZE}\" \\\n",
    "       --model_dir_counter=\"${MODEL_DIR_COUNTER}\" \\\n",
    "       --tpu=\"${TPU_ADDRESS}\" \\\n",
    "       --module_import=caet5.data.tasks \\\n",
    "       --use_model_api=True \\\n",
    "       --mode=\"predict\" \\\n",
    "       --bucket=\"${BUCKET}\" \\\n",
    "       --mixture_or_task=\"${MIXTURE}\" \\\n",
    "       --base_pretrained_model_dir=\"gs://t5-data/pretrained_models/\" \\\n",
    "       --checkpoint_mode=\"latest\" \\\n",
    "       --input_file=\"${PREDICT_INPUTS_PATH}\" \\\n",
    "       --output_file=\"${PREDICT_OUTPUTS_PATH}\" \\\n",
    "       --predict_batch_size=\"${PREDICT_BATCH_SIZE}\" \\\n",
    "       --gin_file=\"dataset.gin\" \\\n",
    "       --gin_file=\"models/cae_bi.gin\" \\\n",
    "       --gin_file=\"infer.gin\" \\\n",
    "       --gin_file=\"${SEQUENCE_LENGTH_GIN}\" \\\n",
    "       --gin_file=\"${CONTROL_CODES_GIN}\" \\\n",
    "       --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '2x2'\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fp5CRSI0n1pI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# The output filename will have the checkpoint appended so we glob to get\n",
    "# the latest.\n",
    "prediction_files = sorted(tf.io.gfile.glob(predict_outputs_path + \"*\"))\n",
    "print(\"\\nPredictions using checkpoint %s:\\n\" % prediction_files[-1].split(\"-\")[-1])\n",
    "with tf.io.gfile.GFile(prediction_files[-1]) as f:\n",
    "    for c, g in zip(comments, f):\n",
    "        if c:\n",
    "            print(\"Initial text: \" + c.split(\"|dst_style:\")[0])\n",
    "            print(\"Generated text: \" + g)\n",
    "            print()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}